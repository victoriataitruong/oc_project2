Tasks:
Build a price monitoring system to monitor http://books.toscrape.com/
While working, store your code in a GitHub repository and make frequent commits. Remember to commit a requirements.txt file, but don’t store your virtual environment in your repository itself. You shouldn’t  commit your CSV files, either. When you have finished, send me a link to your GitHub repository and a ZIP file of the data it generates. Also, please write a README.md file and add it to the repository, so I can run your code successfully and output some data!

Deliverables
A link to a GitHub repository that includes:
All of your application code.
The requirements.txt file, but not the virtual environment itself. 
A README.md file with instructions on how to build and activate the virtual environment and run the application code.
None of the extracted data/images (those should not be included in the repository itself).
A ZIP file containing all the extracted data and associated images in a logical and easy to follow format/structure.

Your deliverables must be named using the following convention: Fullname_#_StartDate_A. The # refers to the number of the project on the path. The start date should be in the mmddyyyy format. If you have multiple deliverables, change the letter at the end (ex. “A” for the first deliverable, “B” for the second deliverable, etc). All deliverables must be publicly accessible.

Presentation
During the oral presentation, your assessor will play the role of Sam, your team leader. The assessor will challenge your decisions, so be prepared to defend your work. The presentation will be structured as follows: 

Presentation of deliverables (15 min) 
Present the application, describe your writing process and highlight the extract, transform, and load sections of the code.
Demonstrate the application to your assessor.
Present ideas for improving the code in the future.
Discussion (10 minutes) 
Playing the role of team leader, the assessor will ask you questions about your methodology and your deliverables. 
Debrief (5 min)
At the end of the session, the assessor will stop playing the role of team leader so that you can debrief together.
---------------------------------------------------
# Pick any single product page on Books to Scrape. Write a Python script that visits this page and extracts the following information:

product_page_url
universal_ product_code (upc)
title
price_including_tax
price_excluding_tax
number_available
product_description
category
review_rating
image_url

Write the data to a CSV file using the above fields as column headings.
# Now that you have obtained the information for one book, you can try and get all of the necessary information for one category. Pick any book category on Books to Scrape. Write a Python script that visits this category page and extracts the product page URL for each book in the category. Then combine this with the work you have completed to extract the product data for all the books in your category and write the data to a single CSV file.

Note: some category pages have more than 20 books listed, so they are spread across different pages (‘pagination’). Your application should be able to handle this scenario automatically!
# Next, please write a script that visits Books to Scrape, extracts all the book categories available, and then extracts product information for all books across all of the different categories.  You should write the data to a separate CSV for each book category.
# Finally, extend your existing work to download and save the image file for each product page that you visit!